{% load static %}

<div class="body-container">
    <div class="ui centered one column grid container">
        <!--<div class="ui vertical buttons row">
            <center>
                <button id="recordButton" class="ui red inverted big button record-button" role="switch">
                    Mic &nbsp;&nbsp;<i class="microphone icon"></i>
                </button>
            </center>
        </div>-->
        <div class="cursor-pointer" id="recordButton">MIC</div>

        <canvas id="axesDiv" class="ui centered" style="width: 800px; height: 388px;"></canvas>
    </div>
</div>

<script>
    // From a series of URL to js files, get an object URL that can be loaded in an
    // AudioWorklet. This is useful to be able to use multiple files (utils, data
    // structure, main DSP, etc.) without either using static imports, eval, manual
    // concatenation with or without a build step, etc.
    function URLFromFiles(files) {
        const promises = files
            .map((file) => fetch(file)
                .then((response) => response.text()));

        return Promise
            .all(promises)
            .then((texts) => {
                texts.unshift("var exports = {};"); // hack to make injected umd modules work
                const text = texts.join('');
                const blob = new Blob([text], { type: "application/javascript" });

                return URL.createObjectURL(blob);
            });
    }
</script>
<script>
    (function () {
        let AudioContext;
        // global var for web audio API AudioContext
        let audioCtx;
        let bufferSize = 8192;
        let mimeType = 'audio/wav';

        try {
            AudioContext = window.AudioContext || window.webkitAudioContext;
            audioCtx = new AudioContext();
        } catch (e) {
            throw "Could not instantiate AudioContext: " + e.message;
        }

        // global var getUserMedia mic stream
        let gumStream;
        // global audio node variables
        let mic;
        let gain;
        let pitchNode;

        // Shared data with AudioWorkletGlobalScope
        let audioReader;

        // Visualization objects
        let animationId;
        let canvas = document.getElementById("axesDiv");
        let pitchAccum = [];
        let rmsAccum = [];
        let refreshRate = bufferSize / audioCtx.sampleRate * 1000;

        let pitchBuffer;
        let finalBuffers = new Float32Array(3);
        let recorder;
        let mediaStream = null

        // calculate time axis labels
        function getTimeLabels(n) {
            // where `n` is number of pitch values or time frames to be represented
            let xlabels = [];
            for (let i = 0; i < n; i++) {
                xlabels.push(Math.round(Math.round(i * refreshRate) / 100) / 10) // time in secs rounded to 1 decimal place
            }
            return xlabels;
        }

        DATA.labels = getTimeLabels(30);

        // console.log("before chart creation");
        // console.log(RMS_ARRAY);
        // console.log(CONFIDENCE_ARRAY);
        let pitchChart = new Chart(canvas.getContext("2d"), {
            "data": DATA,
            "options": OPTIONS
        });
        // console.log("after chart creation");

        // Utils:
        function arraySum(total, num) {
            return total + num;
        }

        function recordingRT() {

            // RecordRTC
            var recordRTC = null;

            var isMimeTypeSupported = (_mimeType) => {
                // if (webrtcDetectedBrowser === 'edge')  return false;

                if (typeof MediaRecorder.isTypeSupported !== 'function') {
                    return true;
                }

                return MediaRecorder.isTypeSupported(_mimeType);
            };

            var mimeType = 'audio/wav';
            var recorderType = StereoAudioRecorder;

            if (isMimeTypeSupported(mimeType) === false) {
                console.log(mimeType, 'is not supported.');
                mimeType = 'audio/wav';

                if (isMimeTypeSupported(mimeType) === false) {
                    console.log(mimeType, 'is not supported.');
                    mimeType = 'audio/wav';

                    if (isMimeTypeSupported(mimeType) === false) {
                        console.log(mimeType, 'is not supported.');

                        // fallback to WebAudio solution
                        mimeType = 'audio/wav';
                        recorderType = StereoAudioRecorder;
                    }
                }
            }

            const rtcSession = {
                type: 'audio',
                mimeType: mimeType,
                recorderType: recorderType,
                audio: true,
                video: false,
                timeSlice: 1,
                checkForInactiveTracks: true,
                numberOfAudioChannels: 1,
                ondataavailable: (blob) => {
                    //socketio.emit('stream_audio', blob); // sends blob to server
                    console.log("sent blob", blob)
                    createWaveFileAndSendToServer(blob)
                },
            };

            console.log('final rtcSession object', rtcSession);

            navigator.getUserMedia(rtcSession, (ms) => {
                // RecordRTC requires "second" parameter named as "options" or "configuration" or "hints"
                mediaStream = ms.clone()
                recorder = RecordRTC(mediaStream, rtcSession);
                recorder.startRecording();
                startAudioProcessing();
            }, () => {
                console.error('An error has occurred while attempting to get user media.');
            });

        }


        function resetChartData() {
            rms_pointer = RMS_ARRAY;
            pitchChart.data.labels = getTimeLabels(30);
            pitchChart.data.datasets[0].data = Array(30).fill(100);
            pitchChart.data.datasets[1].data = Array(30).fill(AXES_PITCHES[0]);
            pitchChart.data.datasets[2].data = Array(30).fill(AXES_PITCHES.slice(-1)[0]);
            pitchChart.update();
        }

        function onRecordClickHandler() {
            let recording = $(this).hasClass("recording");
            if (!recording) {
                $(this).prop("disabled", true);

                resetChartData();
                // start microphone stream using getUserMedia and runs the feature extraction
                startMicRecordStream();
            } else {
                stopMicRecordStream();
            }
        }

        // record native microphone input and do further audio processing on each audio buffer using the given callback functions
        function startMicRecordStream() {
            // if (navigator.mediaDevices.getUserMedia) {
            //     console.log("Initializing audio...");
            //     navigator.mediaDevices.getUserMedia({ audio: true, video: false })
            //         .then(startAudioProcessing)
            //         .catch(function (message) {
            //             throw "Could not access microphone - " + message;
            //         });
            // } else {
            //     throw "Could not access microphone - getUserMedia not available";
            // }

            recordingRT()
            // navigator.mediaDevices.getUserMedia({
            //     video: false,
            //     audio: true
            // }).then(async function (stream) {
            //     recorder = RecordRTC(stream, {
            //         type: 'audio/wav',
            //         mimeType: 'audio/wav'
            //     });
            //     recorder.startRecording();
            //     startAudioProcessing()

            // });
        }


        function startAudioProcessing() {

            audioCtx.audioWorklet.addModule("static/js/processor.js")
                .then(setupAudioGraph)
                .catch(function moduleLoadRejected(msg) {
                    console.log(`There was a problem loading the AudioWorklet module code: \n ${msg}`);
                });
            // set button to stop
            $("#recordButton").addClass("recording");
            $("#recordButton").html('Stop &nbsp;&nbsp;<i class="stop icon"></i>');
            $("#recordButton").prop("disabled", false);
        }

        function setupAudioGraph() {
            let sab = RingBuffer.getStorageForCapacity(3, Float32Array); // capacity: three float32 values [pitch, confidence, rms]
            let rb = new RingBuffer(sab, Float32Array);
            audioReader = new AudioReader(rb);
            // pitchNode = new AudioWorkletNode(audioCtx, 'white-noise-processor', {
            //     processorOptions: {
            //         bufferSize: bufferSize,
            //         sampleRate: audioCtx.sampleRate,
            //     }
            // });

            // try {
            //     pitchNode.port.postMessage({
            //         sab: sab,
            //     });
            // } catch(_){
            //     alert("No SharedArrayBuffer tranfer support, try another browser.");
            //     $("#recordButton").off('click', onRecordClickHandler);
            //     $("#recordButton").prop("disabled", true);
            //     return;
            // }

            // // It seems necessary to connect the stream to a sink for the pipeline to work, contrary to documentataions.
            // // As a workaround, here we create a gain node with zero gain, and connect temp to the system audio output.
            // mic.connect(pitchNode);
            // pitchNode.connect(gain);
            // gain.connect(audioCtx.destination);

            requestAnimationFrame(animatePitch); // start plot animation
        }

        let animationStart = 0;
        let elapsed;
        // draw melspectrogram frames
        function animatePitch(timestamp) {
            // if (animationStart === undefined)
            let pitchBuffer = new Float32Array(3);
            pitchBuffer[0] = finalBuffers[0]
            pitchBuffer[1] = finalBuffers[1]
            pitchBuffer[2] = finalBuffers[2]
            animationId = requestAnimationFrame(animatePitch);
            CONFIDENCE_ARRAY.push(pitchBuffer[1]);
            CONFIDENCE_ARRAY.shift();
            const logRMS = 1 + Math.log10(pitchBuffer[2] + Number.MIN_VALUE) * 0.5;
            rmsAccum.push(logRMS);
            RMS_ARRAY.push(logRMS);
            RMS_ARRAY.shift();
            pitchAccum.push(pitchBuffer[0]);
            pitchChart.data.datasets[0].data.push(pitchBuffer[0]);
            pitchChart.data.datasets[0].data.shift();

            // console.info("before chart update");
            pitchChart.update();
            // console.info("AFTER chart update");
            /* SAB method */
            // let pitchBuffer = new Float32Array(3);
            // if (audioReader.available_read() >= 1) {
            //     let read = audioReader.dequeue(pitchBuffer);
            //     if (read !== 0) {
            //         // console.info("main: ", pitchBuffer[0], pitchBuffer[1], pitchBuffer[2]);
            //         // elapsed = timestamp - animationStart;
            //         // animationStart = timestamp;
            //         // console.info(elapsed);
            //         CONFIDENCE_ARRAY.push(pitchBuffer[1]);
            //         CONFIDENCE_ARRAY.shift();
            //         const logRMS = 1 + Math.log10(pitchBuffer[2] + Number.MIN_VALUE) * 0.5;
            //         rmsAccum.push(logRMS);
            //         RMS_ARRAY.push(logRMS);
            //         RMS_ARRAY.shift();
            //         pitchAccum.push(pitchBuffer[0]);
            //         pitchChart.data.datasets[0].data.push(pitchBuffer[0]);
            //         pitchChart.data.datasets[0].data.shift();

            //         // console.info("before chart update");
            //         pitchChart.update();
            //         // console.info("AFTER chart update");
            //     }
            // }
        }

        function drawFullPitchContour() {
            rms_pointer = rmsAccum;
            pitchChart.data.datasets[0].data = pitchAccum;
            pitchChart.data.datasets[1].data = Array(pitchAccum.length).fill(AXES_PITCHES[0]);
            pitchChart.data.datasets[2].data = Array(pitchAccum.length).fill(AXES_PITCHES.slice(-1)[0]);
            pitchChart.data.labels = getTimeLabels(pitchAccum.length);
            pitchChart.update();
            pitchAccum = [];
            rmsAccum = [];
            console.info("Full pitch contour should be displaying");
        }

        function createWaveFileAndSendToServer(blob) {
            let file = new File([blob], 'audio.wav');
            formData = new FormData();
            formData.append('record', file);
            console.log("Send ", formData, "To server");
            $.ajax({
                url: "{% url 'pitch:audio-process'%}",
                headers: { 'X-CSRFToken': '{{csrf_token}}' },
                type: 'POST',
                data: formData,
                enctype: 'multipart/form-data',
                processData: false,
                contentType: false,
                success: function (data) {
                    console.log("hola?", data);
                    if (data.success) {
                        console.log("ok");
                        let pitches = data.pitch
                        console.log(pitches);
                        pitches.forEach(pitch => {
                            finalBuffers[0] = pitch
                            finalBuffers[1] = 1
                            finalBuffers[2] = 1
                            setTimeout(() => { setupAudioGraph(); }, 50000);

                        });

                    }
                },
                error: function (e) {
                    console.error(e);
                }
            });
        }
        function stopMicRecordStream() {

            if (animationId) {
                //cancelAnimationFrame(animationId);
                //drawFullPitchContour();
            }

            // const sleep = m => new Promise(r => setTimeout(r, m));
            // await sleep(3000);

            recorder.stopRecording(() => {
                console.log("Stop recording!");
                mediaStream.stop();
                //console.log(recorder.save("test"));
                //let blob = recorder.getBlob();
                //createWaveFileAndSendToServer(blob);
                //invokeSaveAsDialog(blob, 'audio.wav');
            });


            // stop mic stream
            // gumStream.getAudioTracks().forEach(function (track) {
            //     track.stop();
            //     gumStream.removeTrack(track);
            // });

            $("#recordButton").removeClass("recording");
            $("#recordButton").html('Mic &nbsp;&nbsp;<i class="microphone icon"></i>');


            // audioCtx.close().then(function () {
            //     // manage button state
            //     $("#recordButton").removeClass("recording");
            //     $("#recordButton").html('Mic &nbsp;&nbsp;<i class="microphone icon"></i>');

            //     // disconnect nodes
            //     // mic.disconnect();
            //     // pitchNode.disconnect();
            //     // gain.disconnect();
            //     mic = undefined;
            //     pitchNode = undefined;
            //     gain = undefined;

            //     console.log("Stopped recording ...");
            // });
        }

        $(document).ready(function () {
            // check for SharedArrayBuffer support:
            // add event listeners to ui objects
            $("#recordButton").on('click', onRecordClickHandler);


            try {
                const testSAB = new SharedArrayBuffer(1);
                delete testSAB;
            } catch (e) {
                if (e instanceof ReferenceError && !crossOriginIsolated) {
                    $("#recordButton").prop("disabled", true);
                    // redirect to cross-origin isolated SAB-capable version on Netlify
                    //window.location = "https://essentiajs-pitchmelodia.netlify.app";
                    return;
                }

                // Unknown malfunction: alert user and offer alternative
                $("#recordButtonContainer").before(`
                <div class="ui message">
                    <div class="header">Unable to run app</div>
                    <p><a href="https://essentiajs-melspectrogram.netlify.app">Check out this version! <i class="external alternate icon"></i><a/></p>
                    <p style="font-weight: 300;"><a href="https://github.com/MTG/essentia.js/issues">Let us know <i class="icon comment"></i></a></p>
                </div>`);
            }
        });
    })();
</script>